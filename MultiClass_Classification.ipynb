{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        ID  PAINTING  mean_fixations_small  mean_saccades_small  \\\n",
       "0       1         1            533.025280           160.423178   \n",
       "1       1         2            959.141261           118.256765   \n",
       "2       1         4            618.470264           157.264000   \n",
       "3       1         6            388.826547           172.173720   \n",
       "4       1         7            416.682170           191.483547   \n",
       "...   ...       ...                   ...                  ...   \n",
       "3433  433        21            413.759201           272.099505   \n",
       "3434  433        22            713.084441           198.303046   \n",
       "3435  433        23            532.374389           233.595994   \n",
       "3436  433        45            562.554638           220.089855   \n",
       "3437  433        47            541.126109           220.010226   \n",
       "\n",
       "      mean_diametro_small  min_fixations_small  min_saccades_small  \\\n",
       "0               40.676603           236.200000          233.062500   \n",
       "1               41.718083           543.625000          224.375000   \n",
       "2               38.525371           257.750000          232.312500   \n",
       "3               38.225977           210.250000          233.500000   \n",
       "4               37.850256           193.333333          235.000000   \n",
       "...                   ...                  ...                 ...   \n",
       "3433            43.226224           200.000000           88.125000   \n",
       "3434            38.480120           196.687500          103.125000   \n",
       "3435            34.061647           193.375000           96.437500   \n",
       "3436            37.764686           128.823529          100.588235   \n",
       "3437            38.175597           180.687500          100.750000   \n",
       "\n",
       "      min_diametro_small  max_fixations_small  max_saccades_small  ...  \\\n",
       "0              39.534199          1303.125000          414.062500  ...   \n",
       "1              37.589233          1859.500000          399.937500  ...   \n",
       "2              33.263347          1465.625000          430.750000  ...   \n",
       "3              33.678094          1061.062500          413.250000  ...   \n",
       "4              34.204060          1107.562500          523.562500  ...   \n",
       "...                  ...                  ...                 ...  ...   \n",
       "3433           14.555465          1131.875000          746.437500  ...   \n",
       "3434           22.076219          1580.875000          638.062500  ...   \n",
       "3435           21.677002          1361.750000          615.187500  ...   \n",
       "3436           22.597800          1371.058824          596.352941  ...   \n",
       "3437           22.556484          1279.750000          635.875000  ...   \n",
       "\n",
       "      min_diametro_full  max_fixations_full  max_saccades_full  \\\n",
       "0             27.994411                2364                621   \n",
       "1             12.425000                2630                565   \n",
       "2             12.917720                2211                653   \n",
       "3             13.638764                1686                637   \n",
       "4             20.995163                1824               1106   \n",
       "...                 ...                 ...                ...   \n",
       "3433          12.056443                2328               1785   \n",
       "3434          11.392264                2558                986   \n",
       "3435          10.814601                2622               1197   \n",
       "3436          10.227341                3272                935   \n",
       "3437          10.928375                1989               1376   \n",
       "\n",
       "      max_diametro_full  std_fixations_full  std_saccades_full  \\\n",
       "0             56.098621          651.847840         161.042347   \n",
       "1             80.965363          829.541125         150.093936   \n",
       "2             55.277233          685.965108         171.631852   \n",
       "3             78.819977          481.533646         177.598579   \n",
       "4             76.008530          534.620834         216.905087   \n",
       "...                 ...                 ...                ...   \n",
       "3433          94.056313          594.567670         371.586232   \n",
       "3434          64.859375          799.131948         242.222748   \n",
       "3435          72.476982          732.873481         269.992910   \n",
       "3436          84.657867          951.873395         235.670440   \n",
       "3437          77.669189          611.532328         264.566116   \n",
       "\n",
       "      std_diametro_full  num_diff_nonzero_fixations_full  \\\n",
       "0             13.344737                               48   \n",
       "1             12.588451                               40   \n",
       "2             14.020381                               51   \n",
       "3             15.688681                               52   \n",
       "4             13.772832                               53   \n",
       "...                 ...                              ...   \n",
       "3433          19.143375                               59   \n",
       "3434          10.201133                               51   \n",
       "3435          10.125300                               70   \n",
       "3436          16.408542                               78   \n",
       "3437          14.669738                               67   \n",
       "\n",
       "      num_diff_nonzero_saccades_full  voto  \n",
       "0                                 35    25  \n",
       "1                                 28    33  \n",
       "2                                 37    37  \n",
       "3                                 38    18  \n",
       "4                                 33    24  \n",
       "...                              ...   ...  \n",
       "3433                             126     4  \n",
       "3434                             100    39  \n",
       "3435                             118     2  \n",
       "3436                             123    47  \n",
       "3437                             118     0  \n",
       "\n",
       "[3438 rows x 45 columns]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Extracted_Features.csv')\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID  PAINTING  mean_fixations_small  mean_saccades_small  \\\n",
      "ID                                                               \n",
      "1  9    1        14             -0.643172             0.661496   \n",
      "   18   1        47              0.938086            -1.319669   \n",
      "   12   1        18             -0.713479             1.243281   \n",
      "   4    1         7             -0.675696             0.830897   \n",
      "   11   1        16             -0.668501             0.796306   \n",
      "\n",
      "       mean_diametro_small  min_fixations_small  min_saccades_small  \\\n",
      "ID                                                                    \n",
      "1  9              0.925817            -0.608643           -0.716069   \n",
      "   18            -0.847919             0.575246            1.014441   \n",
      "   12             0.744559            -0.620419           -0.910815   \n",
      "   4              0.715106            -0.618070           -0.625938   \n",
      "   11             0.826155            -0.615657           -0.939786   \n",
      "\n",
      "       min_diametro_small  max_fixations_small  max_saccades_small  ...  \\\n",
      "ID                                                                  ...   \n",
      "1  9            -0.585237            -0.645109            0.790828  ...   \n",
      "   18           -0.640212             1.120224           -1.029118  ...   \n",
      "   12           -0.370387            -0.788044            0.889244  ...   \n",
      "   4             0.583276            -0.715733            0.850847  ...   \n",
      "   11            0.603316            -0.689420            0.828480  ...   \n",
      "\n",
      "       max_saccades_full  max_diametro_full  std_fixations_full  \\\n",
      "ID                                                                \n",
      "1  9            0.021227           3.460813           -0.702010   \n",
      "   18          -1.103806          -0.242614            1.751954   \n",
      "   12          -0.024259          -0.288009           -0.830603   \n",
      "   4            1.076514          -0.245686           -0.754578   \n",
      "   11           0.976444          -0.208528           -0.693340   \n",
      "\n",
      "       std_saccades_full  std_diametro_full  num_diff_nonzero_fixations_full  \\\n",
      "ID                                                                             \n",
      "1  9            0.448939           3.205116                         0.553800   \n",
      "   18          -1.087323           0.183325                        -1.152724   \n",
      "   12           0.497744           0.042008                         0.340484   \n",
      "   4            0.814486          -0.290981                         1.033760   \n",
      "   11           0.723470          -0.129909                         0.607129   \n",
      "\n",
      "       num_diff_nonzero_saccades_full  voto  Class  Class2  \n",
      "ID                                                          \n",
      "1  9                         0.624583    14      1       0  \n",
      "   18                       -1.223776    14      1       0  \n",
      "   12                        0.954647    25      1       1  \n",
      "   4                         0.426544    24      1       1  \n",
      "   11                        1.218698    24      1       1  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "def normalize_group(group):\n",
    "    scaler = StandardScaler()\n",
    "    group[features] = scaler.fit_transform(group[features])\n",
    "    return group\n",
    "\n",
    "# Raggruppa per 'ID' e applica la funzione di normalizzazione\n",
    "normalized_data = data.groupby('ID').apply(normalize_group)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(normalized_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PAINTING</th>\n",
       "      <th>mean_fixations_small</th>\n",
       "      <th>mean_saccades_small</th>\n",
       "      <th>mean_diametro_small</th>\n",
       "      <th>min_fixations_small</th>\n",
       "      <th>min_saccades_small</th>\n",
       "      <th>min_diametro_small</th>\n",
       "      <th>max_fixations_small</th>\n",
       "      <th>max_saccades_small</th>\n",
       "      <th>...</th>\n",
       "      <th>std_fixations_full</th>\n",
       "      <th>std_saccades_full</th>\n",
       "      <th>std_diametro_full</th>\n",
       "      <th>num_diff_nonzero_fixations_full</th>\n",
       "      <th>num_diff_nonzero_saccades_full</th>\n",
       "      <th>voto</th>\n",
       "      <th>Class</th>\n",
       "      <th>Class2</th>\n",
       "      <th>Binary</th>\n",
       "      <th>Binary2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>163</td>\n",
       "      <td>18</td>\n",
       "      <td>2826.240855</td>\n",
       "      <td>88.202934</td>\n",
       "      <td>49.952083</td>\n",
       "      <td>1758.625000</td>\n",
       "      <td>131.1875</td>\n",
       "      <td>45.188963</td>\n",
       "      <td>3743.9375</td>\n",
       "      <td>300.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>2107.830386</td>\n",
       "      <td>123.692382</td>\n",
       "      <td>6.662681</td>\n",
       "      <td>35</td>\n",
       "      <td>77</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>184</td>\n",
       "      <td>21</td>\n",
       "      <td>2546.795297</td>\n",
       "      <td>97.077505</td>\n",
       "      <td>45.749835</td>\n",
       "      <td>1329.066667</td>\n",
       "      <td>188.0000</td>\n",
       "      <td>42.333895</td>\n",
       "      <td>3726.1250</td>\n",
       "      <td>331.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>2195.293843</td>\n",
       "      <td>135.929582</td>\n",
       "      <td>9.161643</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>232</td>\n",
       "      <td>20</td>\n",
       "      <td>148.378595</td>\n",
       "      <td>298.234303</td>\n",
       "      <td>38.326457</td>\n",
       "      <td>131.312500</td>\n",
       "      <td>126.5625</td>\n",
       "      <td>36.168243</td>\n",
       "      <td>565.7500</td>\n",
       "      <td>676.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>316.570028</td>\n",
       "      <td>266.086387</td>\n",
       "      <td>19.882504</td>\n",
       "      <td>58</td>\n",
       "      <td>131</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>156</td>\n",
       "      <td>22</td>\n",
       "      <td>1990.283964</td>\n",
       "      <td>116.315730</td>\n",
       "      <td>34.568627</td>\n",
       "      <td>566.062500</td>\n",
       "      <td>211.3750</td>\n",
       "      <td>31.052835</td>\n",
       "      <td>3320.4375</td>\n",
       "      <td>446.6875</td>\n",
       "      <td>...</td>\n",
       "      <td>1678.910061</td>\n",
       "      <td>156.164331</td>\n",
       "      <td>7.539028</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>231</td>\n",
       "      <td>23</td>\n",
       "      <td>544.126473</td>\n",
       "      <td>202.186455</td>\n",
       "      <td>34.139307</td>\n",
       "      <td>219.625000</td>\n",
       "      <td>102.9375</td>\n",
       "      <td>31.210755</td>\n",
       "      <td>1544.5000</td>\n",
       "      <td>482.6250</td>\n",
       "      <td>...</td>\n",
       "      <td>932.203004</td>\n",
       "      <td>175.872294</td>\n",
       "      <td>9.457139</td>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  PAINTING  mean_fixations_small  mean_saccades_small  \\\n",
       "1167  163        18           2826.240855            88.202934   \n",
       "1385  184        21           2546.795297            97.077505   \n",
       "1960  232        20            148.378595           298.234303   \n",
       "1080  156        22           1990.283964           116.315730   \n",
       "1945  231        23            544.126473           202.186455   \n",
       "\n",
       "      mean_diametro_small  min_fixations_small  min_saccades_small  \\\n",
       "1167            49.952083          1758.625000            131.1875   \n",
       "1385            45.749835          1329.066667            188.0000   \n",
       "1960            38.326457           131.312500            126.5625   \n",
       "1080            34.568627           566.062500            211.3750   \n",
       "1945            34.139307           219.625000            102.9375   \n",
       "\n",
       "      min_diametro_small  max_fixations_small  max_saccades_small  ...  \\\n",
       "1167           45.188963            3743.9375            300.5625  ...   \n",
       "1385           42.333895            3726.1250            331.1875  ...   \n",
       "1960           36.168243             565.7500            676.5000  ...   \n",
       "1080           31.052835            3320.4375            446.6875  ...   \n",
       "1945           31.210755            1544.5000            482.6250  ...   \n",
       "\n",
       "      std_fixations_full  std_saccades_full  std_diametro_full  \\\n",
       "1167         2107.830386         123.692382           6.662681   \n",
       "1385         2195.293843         135.929582           9.161643   \n",
       "1960          316.570028         266.086387          19.882504   \n",
       "1080         1678.910061         156.164331           7.539028   \n",
       "1945          932.203004         175.872294           9.457139   \n",
       "\n",
       "      num_diff_nonzero_fixations_full  num_diff_nonzero_saccades_full  voto  \\\n",
       "1167                               35                              77    25   \n",
       "1385                               29                              14    13   \n",
       "1960                               58                             131    19   \n",
       "1080                               38                              19    16   \n",
       "1945                               62                              99    22   \n",
       "\n",
       "      Class  Class2  Binary  Binary2  \n",
       "1167      1       1       0        2  \n",
       "1385      1       0       0        0  \n",
       "1960      1       1       0        2  \n",
       "1080      1       1       0        2  \n",
       "1945      1       1       0        2  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['mean_fixations_small', 'mean_saccades_small', 'mean_diametro_small',\n",
    "            'min_fixations_small', 'min_saccades_small', 'min_diametro_small',\n",
    "            'max_fixations_small', 'max_saccades_small', 'max_diametro_small',\n",
    "            'std_fixations_small', 'std_saccades_small', 'std_diametro_small',\n",
    "            'num_diff_nonzero_fixations_small', 'num_diff_nonzero_saccades_small',\n",
    "            'mean_fixations_medium', 'mean_saccades_medium', 'mean_diametro_medium',\n",
    "            'min_fixations_medium', 'min_saccades_medium', 'min_diametro_medium',\n",
    "            'max_fixations_medium', 'max_saccades_medium', 'max_diametro_medium',\n",
    "            'std_fixations_medium', 'std_saccades_medium', 'std_diametro_medium',\n",
    "            'num_diff_nonzero_fixations_medium', 'num_diff_nonzero_saccades_medium',\n",
    "            'mean_fixations_full', 'mean_saccades_full', 'mean_diametro_full',\n",
    "            'min_fixations_full', 'min_saccades_full', 'min_diametro_full',\n",
    "            'max_fixations_full', 'max_saccades_full', 'max_diametro_full',\n",
    "            'std_fixations_full', 'std_saccades_full', 'std_diametro_full',\n",
    "            'num_diff_nonzero_fixations_full', 'num_diff_nonzero_saccades_full']\n",
    "\n",
    "data['Class'] = data['voto'].apply(lambda x: 0 if x <= 12 else 1 if x <= 25 else 2 if x <= 38 else 3 if x <= 50 else None)\n",
    "data['Class2'] = data['voto'].apply(lambda x: 0 if x <= 15 else 1 if x <= 35 else 2 if x <= 50 else None)\n",
    "data['Binary'] = data['voto'].apply(lambda x: 0 if x<=25 else 1)\n",
    "data['Binary2'] = data['voto'].apply(lambda x: 0 if x<=15 else 1 if x>=35 else 2)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data['Class'].dropna(), bins=4, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribuzione delle Classi')\n",
    "plt.xlabel('Classi')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.xticks(ticks=[0.25, 1.1, 1.8, 2.6], labels=['0 (0-12)', '1 (13-25)', '2 (26-38)', '3 (39-50)'])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trova il numero minimo di istanze in una delle classi\n",
    "min_count = data['Class'].value_counts().min()\n",
    "\n",
    "# Crea un nuovo DataFrame bilanciato\n",
    "balanced_data = pd.DataFrame()\n",
    "\n",
    "# Raccolta di subset bilanciati per ogni categoria\n",
    "subsets = []\n",
    "for category in data['Class'].unique():\n",
    "    category_subset = data[data['Class'] == category].sample(n=min_count, random_state=42)\n",
    "    subsets.append(category_subset)\n",
    "\n",
    "# Concatenazione dei subset in un unico DataFrame bilanciato\n",
    "balanced_data = pd.concat(subsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAGDCAYAAACFuAwbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAupUlEQVR4nO3deZxWZ3338c9v9mEZSCCBMEBIBDEkdclD1FatUatVq0arprZVY5o2j0/tavuosdVqW5dutvbpptXGuBtj1VTjkkaN6auNhrgEAkEghBCyERKWgVmZ3/PHuSbe4gBD5OYMzOf9et2vOec617nONfd1bubLWe4TmYkkSZLq01J3ByRJkqY6A5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkh4WEf8SEW85Sm0tjoi+iGgt89+IiF8/Gm03bONpEbH+aLb5CPvxtoj46ATrPvw+RMRrIuK/mtSnprVd2v9SRFzUrPalqcZAJk0REXFHRPRHxJ6I2BkR/x0Rr42Ih/8dyMzXZuafTbCtnztUncy8MzNnZOb+o9H/g2zjhsxc3qz2J7uI+PmI+GYZ0+0RcX1EvOhYbDszn5eZVxyLbUlTgYFMmlpemJkzgdOBdwNvBD54tDcSEW1Hu039qIh4GfBp4MPAQmAe8FbghXX2S9IjYyCTpqDM3JWZVwO/BFwUEecARMSHIuLPy/TciPhCOZr2YETcEBEtEfERYDHwH+WU5BsiYklEZERcEhF3Al9rKGsMZ4+KiG9HxO6I+HxEnFy2dX5E3NXYx8ajcKUPfeW1t7S75MD1IuKsckpwZ0Tc2ni0qPxu/xgRXyxHlL4VEY9qWP6YiLi2/K7rI+LCg71/EXFGORq1JyKuBeYesPzJ5Qjkzoj4fkScP5FxmWgfIiKA9wB/lpkfKOM5mpnXZ+ZvHGSd90bE1vLe3xwRT2tY9sSIWFWW3RcR7ynlXRHx0YjYUX6XmyJiXll21E9BS1OZgUyawjLz28BdwNPGWfwHZdkpVEdf3lytkq8C7qQ62jYjM/+yYZ2nA2cBP3+QTb4a+DXgNGAE+PsJ9nN22dYM4L3ADcC2xjoR0Q78B/BV4FTgt4GPRUTjKc1XAG8HTgI2Au8o604HrgU+XtZ9BfBPEbHiIF36OHAzVRD7M+Dha6kiohf4IvDnwMnAHwKfiYhTDvU7HmEflgOLgKsO1eYBbgIeX/r0ceDTEdFVlr0XeG9m9gCPAq4s5RcBs8q25gCvBfqPYJuSJshAJuluqj/SBxqmCk6nZ+ZwuV7rcA+/fVtm7s3Mg/3R/khmrsnMvcBbgAujXPQ/ERHxS8CvAC/NzOEDFj8ZmAG8OzOHMvNrwBeAX26o89nM/HZmjgAfowooAC8A7sjMyzNzJDO/C3wGePk4fVgMnAe8JTMHM/ObVEFwzCuBazLzmnLU6lpgFfD8w/x6E+4DVTgCuOcwbT4sMz+amTtK238DdFIFO6jGemlEzM3Mvsy8saF8DrA0M/dn5s2ZuXui25Q0cQYySb3Ag+OU/xXVUaSvRsTtEfGmCbS19QiWbwHaOeB038FExBOAfwBekpnbx6myANiamaMHbKO3Yf7ehul9VAEOqmvqnlROy+2MiJ3ArwLzD7Kdh0qobNzOmNOBlx/Q1lOpwu2hHEkfdpSfh2vzYRHxhxGxLiJ2lbZn8cP3/hLg0cBt5bTkC0r5R4CvAJ+MiLsj4i/LkUhJR5kX3kpTWEScRxVYfuzrETJzD9Vpyz8o15h9LSJuyszrgIMdKTvcEbRFDdOLqY7APADsBaY19KuV6lTp2PypwOeA15UjR+O5G1gUES0NoWwx8IPD9AmqoHh9Zj57AnXvAU6KiOkNoWwxP/zdt1IdCRz3Wq6j1If1pf5Lgb8+XOVyvdgbgGcBt2bmaEQ8BARAZm4AfjmqO25/EbgqIuaU3+/twNsjYglwTdn2Ub8RRJrqPEImTUER0VOOgnwS+Ghmrh6nzgsiYmm5gHwXsB8YCzr3AWc+gk2/MiJWRMQ04E+Bq8rXYvwA6IqIXyhHYP6Y6pTa2B2bV5V+XnmwhoFvUR31ekNEtJcL6V9YfsfD+QLw6Ih4VVm3PSLOi4izDqyYmVuoTkG+PSI6IuKp/OidjR8FXhjVV1K0lgvjz4+IhUexDwm8HnhLRFxcxrMlIp4aEe8fp+2ZVNfsbQfaIuKtQM/Ywoh4ZUScUoLszlI8GhHPiIifKgF5N1WAHkXSUWcgk6aW/4iIPVRHV/6I6k69iw9Sdxnwn0Af8D/AP2Xm18uydwF/XE6t/eERbP8jwIeoTh12Ab8D1V2fwG8CH6C6WH8v1Q0FUH2lw9OA34sf3mnZV67lelhmDlEFo+dRHXX7J+DVmXnb4TpVjgY+h+pC+rtL//6CEgrH8SvAk6hO9f4J1VdPjLW1FbiA6iaI7VTv9f/lMP/eHmkfMvMqqrtkf63Uv4/qRoLPj1P9K8CXqYLvFmCAHz19/Fzg1ojoo7rA/xXlOsD5VGF4N7AOuJ5qDCUdZXH4a3QlSZLUTB4hkyRJqpmBTJIkqWYGMkmSpJoZyCRJkmpmIJMkSarZcf3FsHPnzs0lS5bU3Q1JkqTDuvnmmx/IzHGfa3tcB7IlS5awatWqurshSZJ0WBGx5WDLPGUpSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTVraiCLiNkRcVVE3BYR6yLipyPi5Ii4NiI2lJ8nlboREX8fERsj4paIOLeZfZMkSZosmn2E7L3AlzPzMcDjgHXAm4DrMnMZcF2ZB3gesKy8LgX+ucl9kyRJmhSaFsgiYhbws8AHATJzKDN3AhcAV5RqVwAvLtMXAB/Oyo3A7Ig4rVn9kyRJmiyaeYTsDGA7cHlEfDciPhAR04F5mXlPqXMvMK9M9wJbG9a/q5RJkiSd0Jr5LMs24FzgtzPzWxHxXn54ehKAzMyIyCNpNCIupTqlycKFC1m9ejUA8+fPp7u7m82bNwPQ09PD4sWLWbNmDQCtra2sWLGCTZs2sW/fPgCWLl3Krl272L59OwALFiygvb2dLVuqR03NmjWL3t5e1q5dC0B7ezuPecxj2LBhAwMDAwA8+tGPZseOHezYsQOA3t5eWlpa2Lq1ypYnnXQS8+bN47bbbgOgo6OD5cuXs379eoaGhgB4zGMew3333cdDDz0EwKJFixgdHWXbtm0AzJkzhzlz5vCDH/wAgK6uLpYtW8Ztt93G8PAwACtWrGDbtm3s2rULgNNPP53h4WHuvvtuAE455RRmzZrFxo0bAZg2bRqPetSjWLt2Lfv37wfgnHPO4c4772T37t0AnHHGGfT393PvvfcCcOqppzJz5kw2bdoEwIwZMzjjjDNYs2YNmUlEcM4557B582b6+voAeNSjHsWePXu4//77HSfHyXFynBwnx2lKj9OhROYR5aEJi4j5wI2ZuaTMP40qkC0Fzs/Me8opyW9k5vKIeF+Z/kSpv36s3sG2sXLlyvTh4pIk6XgQETdn5srxljXtCFlm3hsRWyNieWauB54FrC2vi4B3l5+fL6tcDfxWRHwSeBKw61Bh7Fh56a+8iju33Vt3N1SDe+/exvwFnjWfihz7qcuxn7oW987nMx//SG3bb+YpS4DfBj4WER3A7cDFVNetXRkRlwBbgAtL3WuA5wMbgX2lbu3u3HYvj734nXV3QzVYf9mFPMexn5Ic+6nLsZ+6brn8zbVuv6mBLDO/B4x3aO5Z49RN4HXN7I8kSdJk5Df1S5Ik1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNmhrIIuKOiFgdEd+LiFWl7OSIuDYiNpSfJ5XyiIi/j4iNEXFLRJzbzL5JkiRNFsfiCNkzMvPxmbmyzL8JuC4zlwHXlXmA5wHLyutS4J+PQd8kSZJqV8cpywuAK8r0FcCLG8o/nJUbgdkRcVoN/ZMkSTqmmh3IEvhqRNwcEZeWsnmZeU+ZvheYV6Z7ga0N695VyiRJkk5obU1u/6mZuS0iTgWujYjbGhdmZkZEHkmDJdhdCrBw4UJWr14NwPz58+nu7mbz5s0A9PT0sHjxYtasWQNAa2srK1asYNOmTezbtw+ApUuXsmvXLrZv3w7AggULaG9vZ8uWLQDMmjWL1tZWzu7eBcBIBusHeljauYfOllEANgzMYE7bECe3DQGwbaibUYJFHdU2do60c99wF8u79wAwlC1sGJjJsq49dETVxvr+mcxrH2B22zAAW4em0ULS29EPwIMjHewY6WBZVx8Ag6MtbBycyfKu3bSVt29dfw+9Hf30tFZt3Dk4jfaWUU5rHwDggZFOdo60s7S00T/ayu2DMzirazctpY1b+3tY3LGPma0jANwxOJ3ulv3MK23cP9xJ32gbZ3buBWDvaBt3DE5/+P2p2pjFks69TG+p2rh9cDozWkY4tX0QgPuGu+gfbWVJaWPP/jbuHJrG2d27ARjNYN1AD2d29tHdsh+AjQMzmN02zNy2qo17hrsYHm1hcWf1Hu/e3862oW7OKm0crXECHKfjYJya8Xn6XFsbizr2OU6TfJya8Xm64dRTmNs26DhN8nFqxudp96KF9PX1HfUc0dvby9q1azmcyDyiPPSIRcTbgD7gN4DzM/OeckryG5m5PCLeV6Y/UeqvH6t3sDZXrlyZq1atamq/z3v6s3nsxe9s6jY0OX36sgt5+buurLsbqoFjP3U59lPXLZe/mZuuv7ap24iImxuuqf8RTTtlGRHTI2Lm2DTwHGANcDVwUal2EfD5Mn018Opyt+WTgV2HCmOSJEknimaespwHfDYixrbz8cz8ckTcBFwZEZcAW4ALS/1rgOcDG4F9wMVN7JskSdKk0bRAlpm3A48bp3wH8KxxyhN4XbP6I0mSNFn5Tf2SJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs2aHsgiojUivhsRXyjzZ0TEtyJiY0R8KiI6Snlnmd9Yli9pdt8kSZImg2NxhOx3gXUN838B/G1mLgUeAi4p5ZcAD5Xyvy31JEmSTnhNDWQRsRD4BeADZT6AZwJXlSpXAC8u0xeUecryZ5X6kiRJJ7S2Jrf/d8AbgJllfg6wMzNHyvxdQG+Z7gW2AmTmSETsKvUfaGwwIi4FLgVYuHAhq1evBmD+/Pl0d3ezefNmAHp6eli8eDFr1qwBoLW1lRUrVrBp0yb27dsHwNKlS9m1axfbt28HYMGCBbS3t7NlyxYAZs2aRWtrK2d37wJgJIP1Az0s7dxDZ8soABsGZjCnbYiT24YA2DbUzSjBoo5qGztH2rlvuIvl3XsAGMoWNgzMZFnXHjqiamN9/0zmtQ8wu20YgK1D02gh6e3oB+DBkQ52jHSwrKsPgMHRFjYOzmR5127aIgFY199Db0c/Pa1VG3cOTqO9ZZTT2gcAeGCkk50j7SwtbfSPtnL74AzO6tpNS2nj1v4eFnfsY2ZrNTx3DE6nu2U/80ob9w930jfaxpmdewHYO9rGHYPTH35/qjZmsaRzL9NbqjZuH5zOjJYRTm0fBOC+4S76R1tZUtrYs7+NO4emcXb3bgBGM1g30MOZnX10t+wHYOPADGa3DTO3rWrjnuEuhkdbWNxZvce797ezbaibs0obR2ucAMfpOBinZnyePtfWxqKOfY7TJB+nZnyebjj1FOa2DTpOk3ycmvF52r1oIX19fUc9R/T29rJ27VoOJzLzsJUeiYh4AfD8zPzNiDgf+EPgNcCN5bQkEbEI+FJmnhMRa4DnZuZdZdkm4EmZ+cB47QOsXLkyV61a1ZT+jznv6c/msRe/s6nb0OT06csu5OXvurLubqgGjv3U5dhPXbdc/mZuuv7apm4jIm7OzJXjLWvmEbKnAC+KiOcDXUAP8F5gdkS0laNkC4Ftpf42YBFwV0S0AbOAHU3snyRJ0qTQtGvIMvOyzFyYmUuAVwBfy8xfBb4OvKxUuwj4fJm+usxTln8tm3X4TpIkaRKp43vI3gi8PiI2Ul0j9sFS/kFgTil/PfCmGvomSZJ0zDX7on4AMvMbwDfK9O3AE8epMwC8/Fj0R5IkaTLxm/olSZJqZiCTJEmqmYFMkiSpZgYySZKkmhnIJEmSamYgkyRJqpmBTJIkqWYGMkmSpJoZyCRJkmpmIJMkSaqZgUySJKlmBjJJkqSaGcgkSZJqZiCTJEmqmYFMkiSpZgYySZKkmhnIJEmSatY2kUoR0QVcApwNdI2VZ+avNalfkiRJU8ZEj5B9BJgP/DxwPbAQ2NOsTkmSJE0lEw1kSzPzLcDezLwC+AXgSc3rliRJ0tQx0UA2XH7ujIhzgFnAqc3pkiRJ0tQyoWvIgPdHxEnAHwNXAzOAtzatV5IkSVPIhAJZZn6gTH4TOLN53ZEkSZp6JnTKMiL2R8S7IyIayr7TvG5JkiRNHRO9huzWUverEXFyKYtD1JckSdIETTSQjWTmG4APADdExP8CsnndkiRJmjomelF/AGTmpyLiVuDjwOKm9UqSJGkKmWgg+/WxicxcExFPAy5oTpckSZKmloneZXlzRPwMsGSi60iSJGliJvosy48AjwK+B+wvxQl8uDndkiRJmjomerRrJbAiM72QX5Ik6Sib6F2Wa6geLi5JkqSjbKJHyOYCayPi28DgWGFmvqgpvZIkSZpCJhrI3tbMTkiSJE1lE73L8vqIOB1Ylpn/GRHTgNbmdk2SJGlqmOizLH8DuAp4XynqBT7XpD5JkiRNKRO9qP91wFOA3QCZuQE4tVmdkiRJmkomGsgGM3NobCYi2vBZlpIkSUfFRAPZ9RHxZqA7Ip4NfBr4j+Z1S5IkaeqYaCB7E7AdWA38b+Aa4I+b1SlJkqSpZKJ3WY4C/1pekiRJOoom+izLzYxzzVhmnnnUeyRJkjTFHMmzLMd0AS8HTj763ZEkSZp6JnQNWWbuaHhty8y/A37hUOtERFdEfDsivh8Rt0bE20v5GRHxrYjYGBGfioiOUt5Z5jeW5Ut+wt9NkiTpuDDRL4Y9t+G1MiJey+GPrg0Cz8zMxwGPB54bEU8G/gL428xcCjwEXFLqXwI8VMr/ttSTJEk64U30lOXfNEyPAHcAFx5qhcxMoK/MtpdXAs8EfqWUX0H1nMx/Bi7gh8/MvAr4h4iI0o4kSdIJa6J3WT7jkTQeEa3AzcBS4B+BTcDOzBwpVe6iegwT5efWsr2RiNgFzAEeOKDNS4FLARYuXMjq1asBmD9/Pt3d3WzevBmAnp4eFi9ezJo1awBobW1lxYoVbNq0iX379gGwdOlSdu3axfbt2wFYsGAB7e3tbNmyBYBZs2bR2trK2d27ABjJYP1AD0s799DZMgrAhoEZzGkb4uS26ntztw11M0qwqKPaxs6Rdu4b7mJ59x4AhrKFDQMzWda1h46o2ljfP5N57QPMbhsGYOvQNFpIejv6AXhwpIMdIx0s66ry7eBoCxsHZ7K8azdtUeXVdf099Hb009NatXHn4DTaW0Y5rX0AgAdGOtk50s7S0kb/aCu3D87grK7dtJQ2bu3vYXHHPma2VsNzx+B0ulv2M6+0cf9wJ32jbZzZuReAvaNt3DE4/eH3p2pjFks69zK9pWrj9sHpzGgZ4dT2QQDuG+6if7SVJaWNPfvbuHNoGmd37wZgNIN1Az2c2dlHd8t+ADYOzGB22zBz26o27hnuYni0hcWd1Xu8e38724a6Oau0cbTGCXCcjoNxasbn6XNtbSzq2Oc4TfJxasbn6YZTT2Fu26DjNMnHqRmfp92LFtLX13fUc0Rvby9r167lcGIiB6Ai4vWHWp6Z7znM+rOBzwJvAT5UTksSEYuAL2XmORGxBnhuZt5Vlm0CnpSZDxykWVauXJmrVq06bP9/Euc9/dk89uJ3NnUbmpw+fdmFvPxdV9bdDdXAsZ+6HPup65bL38xN11/b1G1ExM2ZuXK8ZUdyl+V5wNVl/oXAt4ENE1k5M3dGxNeBnwZmR0RbOUq2ENhWqm0DFgF3lUczzQJ2TLB/kiRJx62JBrKFwLmZuQcgIt4GfDEzX3mwFSLiFGC4hLFu4NlUF+p/HXgZ8EngIuDzZZWry/z/lOVf8/oxSZI0FUw0kM0Dhhrmh0rZoZwGXFGuI2sBrszML0TEWuCTEfHnwHeBD5b6HwQ+EhEbgQeBV0ywb5IkSce1iQayDwPfjojPlvkXU90heVCZeQvwhHHKbweeOE75ANUXzkqSJE0pE73L8h0R8SXgaaXo4sz8bvO6JUmSNHVM6Ithi2nA7sx8L9WF92c0qU+SJElTykS/qf9PgDcCl5WiduCjzeqUJEnSVDLRI2QvAV4E7AXIzLuBmc3qlCRJ0lQy0UA2VL6CIgEiYnrzuiRJkjS1TDSQXRkR76P6UtffAP4T+NfmdUuSJGnqOOxdlhERwKeAxwC7geXAWzOzuc8XkCRJmiIOG8gyMyPimsz8KcAQJkmSdJRN9JTldyLivKb2RJIkaYqa6Df1Pwl4ZUTcQXWnZVAdPHtsszomSZI0VRwykEXE4sy8E/j5Y9QfSZKkKedwR8g+B5ybmVsi4jOZ+dJj0CdJkqQp5XDXkEXD9JnN7IgkSdJUdbhAlgeZliRJ0lFyuFOWj4uI3VRHyrrLNPzwov6epvZOkiRpCjhkIMvM1mPVEUmSpKlqot9DJkmSpCYxkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklSzpgWyiFgUEV+PiLURcWtE/G4pPzkiro2IDeXnSaU8IuLvI2JjRNwSEec2q2+SJEmTSTOPkI0Af5CZK4AnA6+LiBXAm4DrMnMZcF2ZB3gesKy8LgX+uYl9kyRJmjSaFsgy857M/E6Z3gOsA3qBC4ArSrUrgBeX6QuAD2flRmB2RJzWrP5JkiRNFm3HYiMRsQR4AvAtYF5m3lMW3QvMK9O9wNaG1e4qZfc0lBERl1IdQWPhwoWsXr0agPnz59Pd3c3mzZsB6OnpYfHixaxZswaA1tZWVqxYwaZNm9i3bx8AS5cuZdeuXWzfvh2ABQsW0N7ezpYtWwCYNWsWra2tnN29C4CRDNYP9LC0cw+dLaMAbBiYwZy2IU5uGwJg21A3owSLOqpt7Bxp577hLpZ37wFgKFvYMDCTZV176IiqjfX9M5nXPsDstmEAtg5No4Wkt6MfgAdHOtgx0sGyrj4ABkdb2Dg4k+Vdu2mLBGBdfw+9Hf30tFZt3Dk4jfaWUU5rHwDggZFOdo60s7S00T/ayu2DMzirazctpY1b+3tY3LGPma0jANwxOJ3ulv3MK23cP9xJ32gbZ3buBWDvaBt3DE5/+P2p2pjFks69TG+p2rh9cDozWkY4tX0QgPuGu+gfbWVJaWPP/jbuHJrG2d27ARjNYN1AD2d29tHdsh+AjQMzmN02zNy2qo17hrsYHm1hcWf1Hu/e3862oW7OKm0crXECHKfjYJya8Xn6XFsbizr2OU6TfJya8Xm64dRTmNs26DhN8nFqxudp96KF9PX1HfUc0dvby9q1azmcyMzDVvpJRMQM4HrgHZn57xGxMzNnNyx/KDNPiogvAO/OzP8q5dcBb8zMVQdre+XKlblq1UEXHxXnPf3ZPPbidzZ1G5qcPn3Zhbz8XVfW3Q3VwLGfuhz7qeuWy9/MTddf29RtRMTNmblyvGVNvcsyItqBzwAfy8x/L8X3jZ2KLD/vL+XbgEUNqy8sZZIkSSe0Zt5lGcAHgXWZ+Z6GRVcDF5Xpi4DPN5S/utxt+WRgV8OpTUmSpBNWM68hewrwKmB1RHyvlL0ZeDdwZURcAmwBLizLrgGeD2wE9gEXN7FvkiRJk0bTAlm5FiwOsvhZ49RP4HXN6o8kSdJk5Tf1S5Ik1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNmhbIIuLfIuL+iFjTUHZyRFwbERvKz5NKeUTE30fExoi4JSLObVa/JEmSJptmHiH7EPDcA8reBFyXmcuA68o8wPOAZeV1KfDPTeyXJEnSpNK0QJaZ3wQePKD4AuCKMn0F8OKG8g9n5UZgdkSc1qy+SZIkTSbH+hqyeZl5T5m+F5hXpnuBrQ317iplkiRJJ7y2ujacmRkReaTrRcSlVKc1WbhwIatXrwZg/vz5dHd3s3nzZgB6enpYvHgxa9ZUl7C1trayYsUKNm3axL59+wBYunQpu3btYvv27QAsWLCA9vZ2tmzZAsCsWbNobW3l7O5dAIxksH6gh6Wde+hsGQVgw8AM5rQNcXLbEADbhroZJVjUUW1j50g79w13sbx7DwBD2cKGgZks69pDR1RtrO+fybz2AWa3DQOwdWgaLSS9Hf0APDjSwY6RDpZ19QEwONrCxsGZLO/aTVt5C9f199Db0U9Pa9XGnYPTaG8Z5bT2AQAeGOlk50g7S0sb/aOt3D44g7O6dtNS2ri1v4fFHfuY2ToCwB2D0+lu2c+80sb9w530jbZxZudeAPaOtnHH4PSH35+qjVks6dzL9JaqjdsHpzOjZYRT2wcBuG+4i/7RVpaUNvbsb+POoWmc3b0bgNEM1g30cGZnH90t+wHYODCD2W3DzG2r2rhnuIvh0RYWd1bv8e797Wwb6uas0sbRGifAcToOxqkZn6fPtbWxqGOf4zTJx6kZn6cbTj2FuW2DjtMkH6dmfJ52L1pIX1/fUc8Rvb29rF27lsOJzCPORBMWEUuAL2TmOWV+PXB+Zt5TTkl+IzOXR8T7yvQnDqx3qPZXrlyZq1atalr/Ac57+rN57MXvbOo2NDl9+rILefm7rqy7G6qBYz91OfZT1y2Xv5mbrr+2qduIiJszc+V4y471KcurgYvK9EXA5xvKX13utnwysOtwYUySJOlE0bRTlhHxCeB8YG5E3AX8CfBu4MqIuATYAlxYql8DPB/YCOwDLm5WvyRJkiabpgWyzPzlgyx61jh1E3hds/oiSZI0mflN/ZIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUMwOZJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklQzA5kkSVLNDGSSJEk1M5BJkiTVzEAmSZJUs0kVyCLiuRGxPiI2RsSb6u6PJEnSsTBpAllEtAL/CDwPWAH8ckSsqLdXkiRJzTdpAhnwRGBjZt6emUPAJ4ELau6TJElS002mQNYLbG2Yv6uUSZIkndAiM+vuAwAR8TLguZn562X+VcCTMvO3Dqh3KXBpmV0OrD+mHZ3c5gIP1N0JHZfcd05cjq0Oxn3j2Ds9M08Zb0Hbse7JIWwDFjXMLyxlPyIz3w+8/1h16ngSEasyc2Xd/dDxx33nxOXY6mDcNyaXyXTK8iZgWUScEREdwCuAq2vukyRJUtNNmiNkmTkSEb8FfAVoBf4tM2+tuVuSJElNN2kCGUBmXgNcU3c/jmOeytUj5b5z4nJsdTDuG5PIpLmoX5IkaaqaTNeQSZIkTUkGMkmSpJoZyGo20ed3RsTfRcTPlukzIuJbZZ1PlbtSx1vnHRGxNSL6Dih/fUSsjYhbIuK6iDi9lJ8SEV8+mr+fjq6I+LeIuD8i1hym3u9FxKvL9Msj4taIGI2IlQ11nhgR3yuv70fESw7S1q+WfWV1RPx3RDyuYdkdpfx7EbGqofyvI+KZP/lvPDVExKKI+Hr5XN4aEb97iLqNY/tXEXFbGZ/PRsTshnqPjYj/Ke2tjoiucdo66D4QEb9f1l0TEZ8YWz8iPhkRy47qG6CDioiuiPh2GZ9bI+Lth6jb+Hfig2WdWyLiqoiYUcpPL//u3xIR34iIhQdp6zURsb1h//j1hmUXRcSG8rqoofw/I+Kko/fbTzGZ6aumF9XdpJuAM4EO4PvAinHqzQFubJi/EnhFmf4X4P8cpP0nA6cBfQeUPwOYVqb/D/CphmWXA0+p+73xddB95meBc4E1h6jTBtwCtJX5s6i+RPkbwMqGetMa6pwG3D82f0B7PwOcVKafB3yrYdkdwNxx1jkd+Grd79fx8irv/7lleibwg4P8W3Dg2D6nYfovgL84oN7jyvwcoHWc9sbdB6iekrIZ6C7LrgReU6afDvxr3e/ZVHkBAcwo0+3At4Anj1PvwL8TPQ3T7wHeVKY/DVxUpp8JfOQg230N8A/jlJ8M3F5+nlSmx/59uAj4o7rfs+P15RGyek30+Z0vBb4MEBFB9SG6qiy7AnjxeI1n5o2Zec845V/PzH1l9kaqL+Ed8zngV4/4N9ExkZnfBB48TLVnAt/JzJGyzrrM/LEnWmTmvrE6QBcw7h0+mfnfmflQmT1wfzlYP7cAcyJi/uHqCjLznsz8TpneA6xj/EfHHTi2X20Yw8axeQ5wS2Z+v9TbkZn7x9nuofaBNqA7ItqogtvdpfwG4OdKuZosK2NnOdrLa7zP6sN/J8p6u+HhvxndDeusAL5Wpr/OkT8z+ueBazPzwfLvwrXAc8uyq4FfPsL2VBjI6jXR53c+Bbi5TM8Bdjb8I/qTPvPzEuBLDfOrgKf9BO2pfo37yyFFxJMi4lZgNfDahv3qYA7cXxL4akTcXB5r1ug7pS86AhGxBHgC1ZGQAx1qbH+NH47No4GMiK9ExHci4g2H2N6P7QOZuQ34a+BO4B5gV2Z+FSAzR4GNwOMO1qaOrohojYjvUR3BvDYzJ7RvRMTlwL3AY4D/V4q/D/ximX4JMDMi5hxk0y9tOOU59iSdg/7dKgGt8xDt6RAMZMeH04DtR7vRiHglsBL4q4bi+4EFR3tbOqYmvL9k5rcy82zgPOCy8a4zGhMRz6AKZG9sKH5qZp5LdSrzdWPXrxTuS0eoXOfzGeD3xo5wHGDcsY2IPwJGgI+VojbgqVRHu58KvCQinjXeNsfbB8p1QBcAZ1CN4fTy78UYx/YYysz9mfl4qiOgT4yIc8ap9mP7RmZeTDVO64BfKsV/CDw9Ir5Ldfp5G/BjR0+B/wCWZOZjqY6CXTHB7rpvPEIGsnpN6PmdQD/V6QSAHcDshtMFC4FtY/+DKq8/PdyGI+LngD8CXpSZgw2Lusr2dPxq3F8mJDPXAX3AORHxuoZ9aQFUF4gDHwAuyMwdDettKz/vBz5LdRp+jPvSEYiIdqow9rHM/PeDVPuxsY2I1wAvAH41M8dOS90FfDMzHyiXJ1wDnBsRL2kY2x95hmHjPgD8HLA5M7dn5jDw71TXEo5xbGuQmTupTjM+d5zF437uy6nqT1Kd0iQz787MX8zMJ1D9DSAzd0Z1E9j3ypG4sdPcY38bPgD8rzJ9uL9b7huPkIGsXhN9fuc6YClU1xNQfSBfVpZdBHx+7H9Q5fXWQ200Ip4AvI8qjN1/wOJHA4e8g0+T3sP7y6GU/a6tTJ9OdVrjjsz8x4Z96e6IWEz1B/lVmfmDhvWnR8TMsWmq65Ya9x33pQkq1/l8EFiXme85RNUfGduIeC7wBqrP8r6Gel8BfioippUxfjqwNjM/2zC2qw62D1CdqnxyWT+AZ5Vtj3Fsj5Go7n6fXaa7gWcDt41T9eF9IyoPTwMvGlsnIuZGxNjf/suAfwPIzD8a2zdKvdMa2n4RPxz/rwDPiYiTypHU55SysW3Np9qHdIQMZDUq1+uMPb9zHXBljv/8zi8C5zfMvxF4fURspLqm7IPjtR8RfxkRdwHTIuKuiHhbWfRXwAzg0+V/RI0h8Blle5qEIuITwP8Ay8uYXjJOtS9R3Y05ts5Lyn7w08AXI+IrZdFTge+X/xF/FvjNzHxgnPbeSrWf/VP86NdbzAP+KyK+D3wb+GJmjt180k71x2HVOO3pxz0FeBXwzIYjWM8fp96PjC3wD1R3ZV5b1vkXePhanvdQ/afve1Q3Aoz3uR53HyjXKF1FdR3gaqq/Fe8HiIh5QH9m3vsT/s6amNOAr0fELVTjeW1mfmGceo1/JwK4IiJWU43facDYmZPzgfUR8QOqz/A7DrLd34nqaza+D/wO1V2XZOaDwJ+VvtwE/Gkpg+oo2o0TuBZV4/DRSceJiPgv4AXlkHUzt/NNqtNSDx22siatiPgs8IbM3FDT9l9C9TUOb6lj+yeySTC2vw/szsxx/yOo+hyrvxOH2P57gasz87o6tn+88wjZ8eMPgMXN3EBEnAK8xzB2QngT1f+K69IG/E2N2z+R1T22O5n4Bd46tpr+d+Iw1hjGHjmPkEmSJNXMI2SSJEk1M5BJkiTVzEAm6YQWEfOjeiD2pqieKHBNRDw6DvOA9iPcxp+W7/aTpEfEZ5FJOmGV70X6LHBFZr6ilD2O6nb/o+Zw3/0nSYfjETJJJ7JnAMOZ+S9jBeWB2w8/iy8ilkTEDVE98/E7EfEzpfy0iPhm+X6vNRHxtPJEjA+V+dXlKyAoZS87cOOSNFEeIZN0IjuHwz9o/X7g2Zk5EBHLgE9QPeP1V4CvZOY7IqIVmAY8HujNzHMAxr5BXZJ+UgYySVNdO/APEfF4qocsP7qU3wT8W3nqwOcy83sRcTtwZkT8P6pvRv9qHR2WdOLxlKWkE9mt/PChyAfz+8B9wOOojox1AGTmN6keU7QN+FBEvLp8afLjgG8Ar6V66LIk/cQMZJJOZF8DOiPi0rGCiHgssKihzizgnswcpXqeZGupdzpwX2b+K1XwOjci5gItmfkZ4I+Bc4/NryHpROcpS0knrMzM8lzNv4uINwIDwB3A7zVU+yfgMxHxauDLwN5Sfj7wfyNiGOgDXg30ApdHxNh/Zi9r9u8gaWrw0UmSJEk185SlJElSzQxkkiRJNTOQSZIk1cxAJkmSVDMDmSRJUs0MZJIkSTUzkEmSJNXMQCZJklSz/w88MtiqGQ05nQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(balanced_data['Class'].dropna(), bins=4, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribuzione delle Classi')\n",
    "plt.xlabel('Classi')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.xticks(ticks=[0.25, 1.1, 1.8, 2.6], labels=['0 (0-12)', '1 (13-25)', '2 (26-38)', '3 (39-50)'])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN rimossi per classe:\n",
      "Class\n",
      "1    0\n",
      "2    0\n",
      "0    0\n",
      "3    0\n",
      "Name: count, dtype: int64\n",
      "Results for Random Forest:\n",
      "Accuracy: 0.30655391120507397\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.37      0.31       103\n",
      "           1       0.32      0.30      0.31       126\n",
      "           2       0.28      0.24      0.26       120\n",
      "           3       0.37      0.32      0.34       124\n",
      "\n",
      "    accuracy                           0.31       473\n",
      "   macro avg       0.31      0.31      0.31       473\n",
      "weighted avg       0.31      0.31      0.31       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for SVM:\n",
      "Accuracy: 0.26849894291754756\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.45      0.37       103\n",
      "           1       0.21      0.13      0.16       126\n",
      "           2       0.26      0.18      0.21       120\n",
      "           3       0.27      0.35      0.30       124\n",
      "\n",
      "    accuracy                           0.27       473\n",
      "   macro avg       0.26      0.28      0.26       473\n",
      "weighted avg       0.26      0.27      0.25       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.26215644820295986\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.33      0.30       103\n",
      "           1       0.16      0.11      0.13       126\n",
      "           2       0.27      0.28      0.28       120\n",
      "           3       0.30      0.34      0.32       124\n",
      "\n",
      "    accuracy                           0.26       473\n",
      "   macro avg       0.25      0.27      0.26       473\n",
      "weighted avg       0.25      0.26      0.25       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for k-NN:\n",
      "Accuracy: 0.30021141649048627\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.40      0.31       103\n",
      "           1       0.30      0.28      0.29       126\n",
      "           2       0.28      0.23      0.26       120\n",
      "           3       0.38      0.31      0.34       124\n",
      "\n",
      "    accuracy                           0.30       473\n",
      "   macro avg       0.31      0.30      0.30       473\n",
      "weighted avg       0.31      0.30      0.30       473\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "        'SVM': SVC(kernel='linear', probability=True),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'k-NN': KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"Results for {name}:\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "initial_counts = balanced_data['Class'].value_counts()\n",
    "balanced_data = balanced_data.dropna(subset=features + ['Class'])\n",
    "final_counts = balanced_data['Class'].value_counts()\n",
    "nan_removed = initial_counts - final_counts\n",
    "print(\"NaN rimossi per classe:\")\n",
    "print(nan_removed)\n",
    "\n",
    "X = balanced_data[features]\n",
    "y = balanced_data['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_and_evaluate(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data['Class2'].dropna(), bins=3, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribuzione delle Classi')\n",
    "plt.xlabel('Classi')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.xticks(ticks=[0.25, 1.1, 1.8], labels=['0 (0-15)', '1 (16-34)', '2 (35-50)'])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "Accuracy: 0.40380549682875266\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.29      0.32       136\n",
      "           1       0.43      0.57      0.49       190\n",
      "           2       0.39      0.30      0.34       147\n",
      "\n",
      "    accuracy                           0.40       473\n",
      "   macro avg       0.39      0.38      0.38       473\n",
      "weighted avg       0.40      0.40      0.39       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for SVM:\n",
      "Accuracy: 0.39323467230443976\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.01      0.03       136\n",
      "           1       0.41      0.96      0.57       190\n",
      "           2       0.11      0.01      0.02       147\n",
      "\n",
      "    accuracy                           0.39       473\n",
      "   macro avg       0.28      0.33      0.21       473\n",
      "weighted avg       0.29      0.39      0.24       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.38054968287526425\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.15      0.22       136\n",
      "           1       0.40      0.67      0.50       190\n",
      "           2       0.30      0.21      0.25       147\n",
      "\n",
      "    accuracy                           0.38       473\n",
      "   macro avg       0.37      0.35      0.33       473\n",
      "weighted avg       0.37      0.38      0.34       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for k-NN:\n",
      "Accuracy: 0.40380549682875266\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.41      0.36       136\n",
      "           1       0.43      0.46      0.45       190\n",
      "           2       0.47      0.33      0.39       147\n",
      "\n",
      "    accuracy                           0.40       473\n",
      "   macro avg       0.41      0.40      0.40       473\n",
      "weighted avg       0.42      0.40      0.40       473\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = data[features]\n",
    "y = data['Class2']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_and_evaluate(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "152/152 [==============================] - 3s 8ms/step - loss: 1.6565 - accuracy: 0.2626 - val_loss: 1.4026 - val_accuracy: 0.2586\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.4860 - accuracy: 0.2599 - val_loss: 1.3847 - val_accuracy: 0.2559\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4380 - accuracy: 0.2540 - val_loss: 1.3790 - val_accuracy: 0.2612\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4090 - accuracy: 0.2712 - val_loss: 1.3801 - val_accuracy: 0.2639\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4092 - accuracy: 0.2560 - val_loss: 1.3843 - val_accuracy: 0.2401\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3945 - accuracy: 0.2705 - val_loss: 1.3844 - val_accuracy: 0.2427\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3828 - accuracy: 0.2864 - val_loss: 1.3813 - val_accuracy: 0.2401\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3799 - accuracy: 0.2937 - val_loss: 1.3808 - val_accuracy: 0.2348\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3891 - accuracy: 0.2712 - val_loss: 1.3811 - val_accuracy: 0.2427\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3789 - accuracy: 0.2837 - val_loss: 1.3833 - val_accuracy: 0.2427\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 1.3876 - accuracy: 0.2831 - val_loss: 1.3833 - val_accuracy: 0.2586\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3863 - accuracy: 0.2884 - val_loss: 1.3777 - val_accuracy: 0.2665\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3750 - accuracy: 0.2937 - val_loss: 1.3780 - val_accuracy: 0.2480\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3724 - accuracy: 0.3042 - val_loss: 1.3784 - val_accuracy: 0.2507\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3727 - accuracy: 0.2976 - val_loss: 1.3783 - val_accuracy: 0.2691\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3747 - accuracy: 0.2976 - val_loss: 1.3774 - val_accuracy: 0.2850\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.3617 - accuracy: 0.3095 - val_loss: 1.3762 - val_accuracy: 0.2691\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3778 - accuracy: 0.2844 - val_loss: 1.3765 - val_accuracy: 0.2665\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3651 - accuracy: 0.3155 - val_loss: 1.3744 - val_accuracy: 0.2665\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3598 - accuracy: 0.2996 - val_loss: 1.3754 - val_accuracy: 0.2612\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3646 - accuracy: 0.2943 - val_loss: 1.3772 - val_accuracy: 0.2612\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3647 - accuracy: 0.3102 - val_loss: 1.3762 - val_accuracy: 0.2639\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3728 - accuracy: 0.2903 - val_loss: 1.3793 - val_accuracy: 0.2586\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3635 - accuracy: 0.3122 - val_loss: 1.3795 - val_accuracy: 0.2533\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3642 - accuracy: 0.3009 - val_loss: 1.3760 - val_accuracy: 0.2533\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3668 - accuracy: 0.3082 - val_loss: 1.3763 - val_accuracy: 0.2586\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3725 - accuracy: 0.2989 - val_loss: 1.3740 - val_accuracy: 0.2665\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3650 - accuracy: 0.2943 - val_loss: 1.3801 - val_accuracy: 0.2533\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3715 - accuracy: 0.3122 - val_loss: 1.3777 - val_accuracy: 0.2559\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3714 - accuracy: 0.2950 - val_loss: 1.3769 - val_accuracy: 0.2507\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3633 - accuracy: 0.3069 - val_loss: 1.3733 - val_accuracy: 0.2533\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3653 - accuracy: 0.3062 - val_loss: 1.3684 - val_accuracy: 0.2770\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3614 - accuracy: 0.3142 - val_loss: 1.3733 - val_accuracy: 0.2401\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3607 - accuracy: 0.3082 - val_loss: 1.3705 - val_accuracy: 0.2480\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3650 - accuracy: 0.3142 - val_loss: 1.3706 - val_accuracy: 0.2639\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3707 - accuracy: 0.2983 - val_loss: 1.3710 - val_accuracy: 0.2480\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3670 - accuracy: 0.3089 - val_loss: 1.3685 - val_accuracy: 0.2639\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3551 - accuracy: 0.3234 - val_loss: 1.3728 - val_accuracy: 0.2665\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3679 - accuracy: 0.3016 - val_loss: 1.3702 - val_accuracy: 0.2559\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3697 - accuracy: 0.3168 - val_loss: 1.3707 - val_accuracy: 0.2665\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3540 - accuracy: 0.3148 - val_loss: 1.3761 - val_accuracy: 0.2691\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3631 - accuracy: 0.3234 - val_loss: 1.3706 - val_accuracy: 0.2612\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3621 - accuracy: 0.3036 - val_loss: 1.3662 - val_accuracy: 0.2691\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3632 - accuracy: 0.2937 - val_loss: 1.3715 - val_accuracy: 0.2691\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3521 - accuracy: 0.3280 - val_loss: 1.3731 - val_accuracy: 0.2691\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3572 - accuracy: 0.3181 - val_loss: 1.3734 - val_accuracy: 0.2533\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3523 - accuracy: 0.3201 - val_loss: 1.3708 - val_accuracy: 0.2586\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3551 - accuracy: 0.3188 - val_loss: 1.3707 - val_accuracy: 0.2559\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3594 - accuracy: 0.3221 - val_loss: 1.3687 - val_accuracy: 0.2559\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3575 - accuracy: 0.3221 - val_loss: 1.3644 - val_accuracy: 0.2823\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-986bbbe9c104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = data[features]\n",
    "y = data['Class']\n",
    "\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(len(features),), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "152/152 [==============================] - 3s 9ms/step - loss: 1.3353 - accuracy: 0.3373 - val_loss: 1.0936 - val_accuracy: 0.3852\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.1768 - accuracy: 0.3552 - val_loss: 1.0850 - val_accuracy: 0.4274\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1265 - accuracy: 0.3704 - val_loss: 1.0822 - val_accuracy: 0.4380\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1208 - accuracy: 0.3757 - val_loss: 1.0806 - val_accuracy: 0.4248\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1091 - accuracy: 0.3816 - val_loss: 1.0799 - val_accuracy: 0.4248\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1024 - accuracy: 0.3796 - val_loss: 1.0794 - val_accuracy: 0.4090\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0939 - accuracy: 0.3935 - val_loss: 1.0778 - val_accuracy: 0.4248\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0880 - accuracy: 0.4041 - val_loss: 1.0784 - val_accuracy: 0.4274\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0858 - accuracy: 0.3915 - val_loss: 1.0762 - val_accuracy: 0.4354\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0843 - accuracy: 0.3975 - val_loss: 1.0756 - val_accuracy: 0.4406\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0844 - accuracy: 0.4041 - val_loss: 1.0739 - val_accuracy: 0.4459\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0824 - accuracy: 0.4048 - val_loss: 1.0740 - val_accuracy: 0.4406\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0865 - accuracy: 0.4008 - val_loss: 1.0760 - val_accuracy: 0.4274\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0824 - accuracy: 0.3988 - val_loss: 1.0724 - val_accuracy: 0.4459\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0774 - accuracy: 0.4028 - val_loss: 1.0712 - val_accuracy: 0.4327\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0843 - accuracy: 0.3995 - val_loss: 1.0721 - val_accuracy: 0.4248\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0800 - accuracy: 0.4034 - val_loss: 1.0716 - val_accuracy: 0.4301\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0814 - accuracy: 0.4021 - val_loss: 1.0705 - val_accuracy: 0.4459\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0749 - accuracy: 0.4067 - val_loss: 1.0688 - val_accuracy: 0.4459\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0783 - accuracy: 0.4259 - val_loss: 1.0679 - val_accuracy: 0.4354\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0850 - accuracy: 0.3962 - val_loss: 1.0658 - val_accuracy: 0.4538\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0799 - accuracy: 0.4187 - val_loss: 1.0674 - val_accuracy: 0.4697\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0718 - accuracy: 0.4140 - val_loss: 1.0651 - val_accuracy: 0.4617\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0715 - accuracy: 0.4127 - val_loss: 1.0637 - val_accuracy: 0.4485\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0756 - accuracy: 0.4173 - val_loss: 1.0651 - val_accuracy: 0.4512\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0700 - accuracy: 0.4233 - val_loss: 1.0643 - val_accuracy: 0.4565\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.0679 - accuracy: 0.4180 - val_loss: 1.0612 - val_accuracy: 0.4565\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0821 - accuracy: 0.4067 - val_loss: 1.0674 - val_accuracy: 0.4485\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0766 - accuracy: 0.4094 - val_loss: 1.0641 - val_accuracy: 0.4459\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0683 - accuracy: 0.4259 - val_loss: 1.0639 - val_accuracy: 0.4538\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0751 - accuracy: 0.4187 - val_loss: 1.0637 - val_accuracy: 0.4433\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0741 - accuracy: 0.4239 - val_loss: 1.0645 - val_accuracy: 0.4433\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.0733 - accuracy: 0.4187 - val_loss: 1.0626 - val_accuracy: 0.4485\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.0667 - accuracy: 0.4266 - val_loss: 1.0625 - val_accuracy: 0.4433\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0687 - accuracy: 0.4266 - val_loss: 1.0606 - val_accuracy: 0.4459\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.0692 - accuracy: 0.4272 - val_loss: 1.0625 - val_accuracy: 0.4485\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0600 - accuracy: 0.4332 - val_loss: 1.0579 - val_accuracy: 0.4538\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0638 - accuracy: 0.4193 - val_loss: 1.0594 - val_accuracy: 0.4459\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0664 - accuracy: 0.4266 - val_loss: 1.0582 - val_accuracy: 0.4433\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0726 - accuracy: 0.4167 - val_loss: 1.0605 - val_accuracy: 0.4459\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0675 - accuracy: 0.4213 - val_loss: 1.0627 - val_accuracy: 0.4485\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0647 - accuracy: 0.4299 - val_loss: 1.0624 - val_accuracy: 0.4354\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0635 - accuracy: 0.4193 - val_loss: 1.0624 - val_accuracy: 0.4459\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0703 - accuracy: 0.4140 - val_loss: 1.0620 - val_accuracy: 0.4485\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0663 - accuracy: 0.4299 - val_loss: 1.0659 - val_accuracy: 0.4433\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0682 - accuracy: 0.4200 - val_loss: 1.0604 - val_accuracy: 0.4512\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0658 - accuracy: 0.4306 - val_loss: 1.0585 - val_accuracy: 0.4485\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0662 - accuracy: 0.4365 - val_loss: 1.0568 - val_accuracy: 0.4433\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0596 - accuracy: 0.4372 - val_loss: 1.0561 - val_accuracy: 0.4644\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0601 - accuracy: 0.4418 - val_loss: 1.0566 - val_accuracy: 0.4591\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0766 - accuracy: 0.3975\n",
      "Test Loss: 1.0766017436981201\n",
      "Test Accuracy: 0.39746299386024475\n"
     ]
    }
   ],
   "source": [
    "X = data[features]\n",
    "y = data['Class2']\n",
    "\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(len(features),), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentuali di ciascuna classe nel dataset:\n",
      "Class\n",
      "1    25.042301\n",
      "2    25.042301\n",
      "0    25.042301\n",
      "3    24.873096\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = data['Class'].value_counts()\n",
    "total_instances = len(data)\n",
    "class_percentages = (class_counts / total_instances) * 100\n",
    "print(\"Percentuali di ciascuna classe nel dataset:\")\n",
    "print(class_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentuali di ciascuna classe nel dataset:\n",
      "Class2\n",
      "1    39.932318\n",
      "2    30.076142\n",
      "0    29.991540\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = data['Class2'].value_counts()\n",
    "total_instances = len(data)\n",
    "class_percentages = (class_counts / total_instances) * 100\n",
    "print(\"Percentuali di ciascuna classe nel dataset:\")\n",
    "print(class_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "Accuracy: 0.36363636363636365\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.15      0.21       155\n",
      "           1       0.40      0.67      0.50       186\n",
      "           2       0.28      0.17      0.21       132\n",
      "\n",
      "    accuracy                           0.36       473\n",
      "   macro avg       0.33      0.33      0.31       473\n",
      "weighted avg       0.34      0.36      0.32       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for SVM:\n",
      "Accuracy: 0.39323467230443976\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       155\n",
      "           1       0.39      1.00      0.56       186\n",
      "           2       0.00      0.00      0.00       132\n",
      "\n",
      "    accuracy                           0.39       473\n",
      "   macro avg       0.13      0.33      0.19       473\n",
      "weighted avg       0.15      0.39      0.22       473\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression:\n",
      "Accuracy: 0.3890063424947146\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.16      0.22       155\n",
      "           1       0.41      0.76      0.53       186\n",
      "           2       0.33      0.14      0.19       132\n",
      "\n",
      "    accuracy                           0.39       473\n",
      "   macro avg       0.36      0.35      0.31       473\n",
      "weighted avg       0.37      0.39      0.33       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for k-NN:\n",
      "Accuracy: 0.3594080338266385\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.37      0.35       155\n",
      "           1       0.42      0.52      0.46       186\n",
      "           2       0.24      0.13      0.17       132\n",
      "\n",
      "    accuracy                           0.36       473\n",
      "   macro avg       0.33      0.34      0.33       473\n",
      "weighted avg       0.34      0.36      0.34       473\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = normalized_data[features]\n",
    "y = normalized_data['Class2']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_and_evaluate(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "Accuracy: 0.3171247357293869\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.41      0.34       103\n",
      "           1       0.31      0.30      0.31       126\n",
      "           2       0.28      0.23      0.26       120\n",
      "           3       0.38      0.34      0.36       124\n",
      "\n",
      "    accuracy                           0.32       473\n",
      "   macro avg       0.32      0.32      0.32       473\n",
      "weighted avg       0.32      0.32      0.32       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for SVM:\n",
      "Accuracy: 0.26849894291754756\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.45      0.37       103\n",
      "           1       0.21      0.13      0.16       126\n",
      "           2       0.26      0.18      0.21       120\n",
      "           3       0.27      0.35      0.30       124\n",
      "\n",
      "    accuracy                           0.27       473\n",
      "   macro avg       0.26      0.28      0.26       473\n",
      "weighted avg       0.26      0.27      0.25       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.26215644820295986\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.33      0.30       103\n",
      "           1       0.16      0.11      0.13       126\n",
      "           2       0.27      0.28      0.28       120\n",
      "           3       0.30      0.34      0.32       124\n",
      "\n",
      "    accuracy                           0.26       473\n",
      "   macro avg       0.25      0.27      0.26       473\n",
      "weighted avg       0.25      0.26      0.25       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for k-NN:\n",
      "Accuracy: 0.30021141649048627\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.40      0.31       103\n",
      "           1       0.30      0.28      0.29       126\n",
      "           2       0.28      0.23      0.26       120\n",
      "           3       0.38      0.31      0.34       124\n",
      "\n",
      "    accuracy                           0.30       473\n",
      "   macro avg       0.31      0.30      0.30       473\n",
      "weighted avg       0.31      0.30      0.30       473\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = data[features]\n",
    "y = data['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_and_evaluate(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "Accuracy: 0.5687103594080338\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.66      0.60       229\n",
      "           1       0.60      0.48      0.54       244\n",
      "\n",
      "    accuracy                           0.57       473\n",
      "   macro avg       0.57      0.57      0.57       473\n",
      "weighted avg       0.57      0.57      0.57       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for SVM:\n",
      "Accuracy: 0.5116279069767442\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.55      0.52       229\n",
      "           1       0.53      0.48      0.50       244\n",
      "\n",
      "    accuracy                           0.51       473\n",
      "   macro avg       0.51      0.51      0.51       473\n",
      "weighted avg       0.51      0.51      0.51       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.5031712473572939\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.47      0.48       229\n",
      "           1       0.52      0.53      0.53       244\n",
      "\n",
      "    accuracy                           0.50       473\n",
      "   macro avg       0.50      0.50      0.50       473\n",
      "weighted avg       0.50      0.50      0.50       473\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for k-NN:\n",
      "Accuracy: 0.5560253699788583\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.56       229\n",
      "           1       0.57      0.54      0.56       244\n",
      "\n",
      "    accuracy                           0.56       473\n",
      "   macro avg       0.56      0.56      0.56       473\n",
      "weighted avg       0.56      0.56      0.56       473\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = data[features]\n",
    "y = data['Binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_and_evaluate(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "Accuracy: 0.5918367346938775\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57       149\n",
      "           1       0.58      0.64      0.61       145\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.59      0.59      0.59       294\n",
      "weighted avg       0.59      0.59      0.59       294\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for SVM:\n",
      "Accuracy: 0.5136054421768708\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.44      0.48       149\n",
      "           1       0.51      0.59      0.55       145\n",
      "\n",
      "    accuracy                           0.51       294\n",
      "   macro avg       0.52      0.51      0.51       294\n",
      "weighted avg       0.52      0.51      0.51       294\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.5238095238095238\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.46      0.50       149\n",
      "           1       0.52      0.59      0.55       145\n",
      "\n",
      "    accuracy                           0.52       294\n",
      "   macro avg       0.53      0.52      0.52       294\n",
      "weighted avg       0.53      0.52      0.52       294\n",
      "\n",
      "---------------------------------------------------\n",
      "Results for k-NN:\n",
      "Accuracy: 0.5986394557823129\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       149\n",
      "           1       0.58      0.66      0.62       145\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.60      0.60      0.60       294\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "datat = data[data['Binary2'] != 2]\n",
    "\n",
    "X = datat[features]\n",
    "y = datat['Binary2']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_and_evaluate(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
