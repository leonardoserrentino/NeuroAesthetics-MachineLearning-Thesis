{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfel\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soggetti = [1,2,6,7,8,9,11,12,25,26,27,28,29,30,37,38,39,44,\n",
    "            48,49,52,53,54,56,57,58,59,61,72,76,77,80,81,85,\n",
    "            86,88,89,91,92,100,110,111,117,118,119,121,122,\n",
    "            124,125,127,131,132,133,136,138,139,140,144,147,\n",
    "            156,157,158,159,162,163,164,165,166,168,169,170,\n",
    "            171,174,175,181,183,184,192,193,194,196,197,198,\n",
    "            199,200,202,203,204,205,206,207,209,210,211,212,\n",
    "            213,215,216,217,218,220,221,222,224,225,229,230,\n",
    "            231,232,237,238,241,244,245,246,256,257,260,263,\n",
    "            264,270,271,274,275,277,278,279,280,284,285,286,\n",
    "            287,288,290,291,292,293,294,295,296,297,310,311,\n",
    "            317,322,323,324,326,327,329,330,331,332,333,334,\n",
    "            336,337,338,339,341,345,346,347,348,349,350,351,\n",
    "            354,356,357,358,359,360,361,365,371,376,377,387,\n",
    "            388,389,391,393,394,404,409,410,412,413,433]\n",
    "\n",
    "quadri = [1,2,4,6,7,9,10,11,13,14,15,16,18,20,21,22,23,45,47]\n",
    "\n",
    "folder_path = 'coords_filtered/'\n",
    "\n",
    "dfeat = pd.read_csv('Extracted_Features.csv')\n",
    "# Imposta le prime due colonne come indice\n",
    "dfeat.set_index(['ID', 'PAINTING'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_fixations(df, max_dispersion=15, min_duration_points=4):\n",
    "    fixations = []\n",
    "    start_index = 0\n",
    "\n",
    "    while start_index < len(df):\n",
    "        # Inizializza la fixation corrente\n",
    "        current_fixation = [df.iloc[start_index]]\n",
    "        i = start_index + 1\n",
    "\n",
    "        while i < len(df):\n",
    "            # Aggiungi il punto corrente alla fixation se la dispersione è inferiore alla soglia\n",
    "            current_fixation.append(df.iloc[i])\n",
    "            fixation_df = pd.DataFrame(current_fixation)\n",
    "            \n",
    "            # Controlla se la dispersione corrente supera la soglia\n",
    "            if (fixation_df['x'].max() - fixation_df['x'].min() > max_dispersion or\n",
    "                fixation_df['y'].max() - fixation_df['y'].min() > max_dispersion):\n",
    "                # Rimuovi l'ultimo punto aggiunto se supera la dispersione\n",
    "                current_fixation.pop()\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        # Controlla se la fixation ha una durata sufficiente\n",
    "        if len(current_fixation) >= min_duration_points:\n",
    "            fixation_x = pd.DataFrame(current_fixation)['x'].mean()\n",
    "            fixation_y = pd.DataFrame(current_fixation)['y'].mean()\n",
    "            duration = len(current_fixation) * 250  # ogni punto rappresenta 250 ms\n",
    "            fixations.append((fixation_x, fixation_y, duration))\n",
    "\n",
    "        # Aggiorna l'indice di partenza per la prossima fixation\n",
    "        start_index = i if i > start_index + 1 else start_index + 1\n",
    "\n",
    "    return fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_list(data):\n",
    "    df = pd.DataFrame(data, columns=['x', 'y', 'duration'])\n",
    "    \n",
    "    if len(df) < 2:\n",
    "        return None  # Non abbastanza dati per clusterizzare\n",
    "    \n",
    "    max_k = int(np.sqrt(len(df)))  # Calcolo di un massimo ragionevole per k\n",
    "    silhouette_scores = {}\n",
    "    \n",
    "    for k in range(2, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(df[['x', 'y']])\n",
    "        score = silhouette_score(df[['x', 'y']], labels)\n",
    "        silhouette_scores[k] = score\n",
    "        \n",
    "    if not silhouette_scores:\n",
    "        return None  # Impossibile calcolare un punteggio significativo\n",
    "    \n",
    "    optimal_k = max(silhouette_scores, key=silhouette_scores.get)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(df[['x', 'y']])\n",
    "    \n",
    "    # Calcolo delle statistiche per ogni cluster\n",
    "    cluster_stats = df.groupby('cluster')['duration'].agg(['sum', 'count']).reset_index()\n",
    "    cluster_stats.columns = ['Cluster ID', 'Total Duration', 'Number of Points']\n",
    "    \n",
    "    # Trova il cluster con il maggior numero di elementi\n",
    "    max_cluster = cluster_stats.loc[cluster_stats['Number of Points'].idxmax()]\n",
    "    \n",
    "    return {\n",
    "        'max_similar_fixations': max_cluster['Number of Points'],\n",
    "        'max_durata_similar_fixations': max_cluster['Total Duration'],\n",
    "        'n_aree_interesse': optimal_k\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "data = []\n",
    "\n",
    "for s in soggetti:\n",
    "    try:\n",
    "        dp = pd.read_csv(f'ProcessingCSV/SoggettoQuadro/PupilData/S{s}_Qblank.csv')\n",
    "        max_diam_blank = dp['DIAM'].max()\n",
    "    except:\n",
    "        print(f'blank di {s} non presente')\n",
    "    for q in quadri:\n",
    "        try:\n",
    "            #Carico il dataframe con le coordinate appartenenti al solo quadro\n",
    "            dt = pd.read_csv(f'{folder_path}S{s}_Q{q}.csv')\n",
    "            punti_nel_quadro = dt.shape[0] #Il numero di righe sono il numero coordinate appartenenti al quadro\n",
    "\n",
    "            '''Per ogni soggetto x quadro mi calcolo le fixations e le loro coordinate in un dataframe\n",
    "            Per ogni fixation avrò x, y, durata.\n",
    "            Userò la deviazione standard delle coordinate per definire il threshold per la dispersione delle coordinate\n",
    "            Per il threshold della durata userò 2000ms, 8 istanze contigue, ovvero 2 secondi'''\n",
    "            #Calcolo le fixations sul dataset filtered\n",
    "            # Calcolo delle deviazioni standard per x e y\n",
    "            rng_x = dt['x'].max() - dt['x'].min()\n",
    "            rng_y = dt['y'].max() - dt['y'].min()\n",
    "\n",
    "            dispersion_threshold = math.sqrt((rng_x/20)**2 +(rng_y/20)**2)/2\n",
    "            duration_threshold = 8\n",
    "\n",
    "            fixations = calculate_fixations(dt, max_dispersion=dispersion_threshold, min_duration_points=duration_threshold)\n",
    "\n",
    "            result = analyze_list(fixations)\n",
    "\n",
    "            max_similar_fixations, max_durata_similar_fixations, n_aree_interesse = result['max_similar_fixations'], result['max_durata_similar_fixations'], result['n_aree_interesse']\n",
    "\n",
    "            #Copio le features estratte nel dataframe Extrated_Features per diametro pupilla sulla finestra full\n",
    "            mean_diam_pupilla = dfeat.loc[(s,q), 'mean_diametro_full']\n",
    "            min_diam_pupilla = dfeat.loc[(s,q), 'min_diametro_full']\n",
    "            max_diam_pupilla = dfeat.loc[(s,q), 'max_diametro_full']\n",
    "            std_diam_pupilla = dfeat.loc[(s,q), 'std_diametro_full']\n",
    "            diff_max_quadro_blank = dfeat.loc[(s,q), 'max_diametro_full'] - max_diam_blank\n",
    "\n",
    "            istanza = {\n",
    "                'ID' : s,\n",
    "                'PAINTING' : q,\n",
    "                'PUNTI_NEL_QUADRO' : punti_nel_quadro,\n",
    "                'FIXATIONS' : len(fixations),\n",
    "                'mean_diam_pupilla' : mean_diam_pupilla,\n",
    "                'min_diam_pupilla' : min_diam_pupilla,\n",
    "                'max_diam_pupilla' : max_diam_pupilla,\n",
    "                'std_diam_pupilla' : std_diam_pupilla,\n",
    "                'diff_max_quadro_blank' : diff_max_quadro_blank,\n",
    "                'max_similar_fixations' : max_similar_fixations,\n",
    "                'max_durata_similar_fixations' : max_durata_similar_fixations,\n",
    "                'n_aree_interesse' : n_aree_interesse\n",
    "            }\n",
    "\n",
    "            data.append(istanza)\n",
    "        except:\n",
    "            print(f'Errore in soggetto {s} quadro {q}')\n",
    "df = pd.concat([pd.DataFrame([d]) for d in data], ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_list(data):\n",
    "    df = pd.DataFrame(data, columns=['x', 'y', 'duration'])\n",
    "    \n",
    "    if len(df) < 2:\n",
    "        return None  # Non abbastanza dati per clusterizzare\n",
    "    \n",
    "    max_k = int(np.sqrt(len(df)))  # Calcolo di un massimo ragionevole per k\n",
    "    silhouette_scores = {}\n",
    "    \n",
    "    for k in range(2, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(df[['x', 'y']])\n",
    "        score = silhouette_score(df[['x', 'y']], labels)\n",
    "        silhouette_scores[k] = score\n",
    "        \n",
    "    if not silhouette_scores:\n",
    "        return None  # Impossibile calcolare un punteggio significativo\n",
    "    \n",
    "    optimal_k = max(silhouette_scores, key=silhouette_scores.get)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(df[['x', 'y']])\n",
    "    \n",
    "    cluster_info = df.groupby('cluster')['duration'].agg(['sum', 'count']).reset_index()\n",
    "    cluster_info.columns = ['Cluster ID', 'Total Duration', 'Number of Points']\n",
    "    \n",
    "    return cluster_info, optimal_k\n",
    "\n",
    "# Applicazione su tutte le liste\n",
    "results = [analyze_list(fixations)]  # Filtraggio delle liste vuote\n",
    "\n",
    "# Visualizzazione di un esempio di risultato (assicurarsi che ci siano risultati)\n",
    "if results:\n",
    "    print(results[0])  # Mostra il risultato per la prima lista\n",
    "else:\n",
    "    print(\"Nessun risultato disponibile per la visualizzazione\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Extracted_Features_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ProcessingCSV/SoggettoQuadro/PupilData/S1_Qblank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ists = []\n",
    "# Carica la configurazione di TSFEL\n",
    "cfg = tsfel.get_features_by_domain()\n",
    "\n",
    "# DataFrame finale per raccogliere tutte le features\n",
    "all_features = pd.DataFrame()\n",
    "for s in soggetti:\n",
    "    for q in quadri:\n",
    "        try:\n",
    "            df = pd.read_csv(f'ProcessingCSV/SoggettoQuadro/PupilData/S{s}_Q{q}.csv')\n",
    "\n",
    "            ts = df['DIAM']\n",
    "                \n",
    "            # Estrazione delle features\n",
    "            features = tsfel.time_series_features_extractor(cfg, ts, verbose=0)\n",
    "                \n",
    "            istanza={\n",
    "                'ID' : s,\n",
    "                'PAINTING' : q\n",
    "            }\n",
    "\n",
    "            ists.append(istanza)\n",
    "                \n",
    "            # Appendi al DataFrame finale\n",
    "            all_features = pd.concat([all_features, features], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f'Errore in soggetto {s} quadro {q}')\n",
    "            print(e)\n",
    "\n",
    "istanze = pd.concat([pd.DataFrame([i]) for i in ists], ignore_index=True)\n",
    "\n",
    "if len(all_features) == len(istanze):\n",
    "    # Concatena le colonne\n",
    "    result = pd.concat([istanze, all_features], axis=1)\n",
    "else:\n",
    "    print(\"I DataFrame non hanno la stessa lunghezza e non possono essere concatenati.\")\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('Diam_Extracted_Features_TimeSerie.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
